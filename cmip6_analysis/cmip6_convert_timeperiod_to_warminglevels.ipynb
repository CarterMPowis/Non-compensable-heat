{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652a60a9-719c-441f-b613-e16b841ea2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import glob\n",
    "from global_land_mask import globe\n",
    "import pandas as pd\n",
    "import rioxarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f6838-8346-4bc9-8e71-824043235f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model warming levels dict. These are the central years relating to the 21-year warming levels in\n",
    "# the levels list.\n",
    "model_wl_dict = {'ACCESS-CM2':   [2015, 2027, 2040, 2049, 2056, 2066], \n",
    "                 'ACCESS-ESM1-5': [2017, 2029, 2039, 2052, 2063, 2069],\n",
    "                 'CNRM-CM6-1':   [2019, 2031, 2045, 2052, 2059, 2066], \n",
    "                 'CNRM-ESM2-1':  [2024, 2035, 2047, 2056, 2066, 2074], \n",
    "                 'CanESM5':      [1998, 2013, 2026, 2031, 2040, 2049],\n",
    "                 'EC-Earth3-Veg-LR':[2007, 2031, 2044, 2056, 2064, 2069],\n",
    "                 'FGOALS-g3':    [2006, 2030, 2047, 2054, 2074, 2087], \n",
    "                 'GFDL-CM4':     [2017, 2029, 2044, 2052, 2059, 2072],\n",
    "                 'INM-CM4-8':    [2016, 2029, 2045, 2059, 2070, 2086], \n",
    "                 'INM-CM5-0':    [2019, 2035, 2048, 2065, 2072, 2090], \n",
    "                 'IPSL-CM6A-LR': [2008, 2023, 2038, 2043, 2051, 2062],\n",
    "                 'MIROC-ES2L':   [2023, 2039, 2052, 2061, 2073, 2087], \n",
    "                 'MIROC6':       [2024, 2043, 2054, 2069, 2079, 2089], \n",
    "                 'MPI-ESM1-2-HR':[2016, 2034, 2053, 2063, 2076, 2087],\n",
    "                 'MPI-ESM1-2-LR':[2021, 2037, 2052, 2061, 2074, 2083], \n",
    "                 'MRI-ESM2-0':   [2015, 2027, 2037, 2055, 2065, 2073]}\n",
    "levels = [1, 1.5, 2, 2.5, 3, 3.5,]\n",
    "window_size = 10\n",
    "model_names = list(model_wl_dict)\n",
    "n_models = len(model_names)\n",
    "n_wl = len(levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef4f1bf-82d6-46f9-91ef-cf3bccefa33c",
   "metadata": {},
   "source": [
    "### Convert for each model individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316af935-1dbd-4e02-8faa-5f02c4d7cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template filenames\n",
    "fp_temp = '<filename template (full path) for tolh files>'\n",
    "fp_out_temp = './output/<filename template>'\n",
    "nday_list = [3, 6, 9, 12, 15, 18, 21, 24]\n",
    "\n",
    "for ii, model in enumerate(model_names):\n",
    "    print(ii+1, n_models, end='\\r')\n",
    "    fp_ii = fp_temp.format(model)\n",
    "    ds_ii = xr.open_dataset(fp_ii).load()\n",
    "    ds_out = ds_ii[['lon','lat']]\n",
    "    ds_out['level'] = (['level'], levels)\n",
    "    \n",
    "    for ndays in nday_list:\n",
    "        n_lon = ds_ii.dims['lon']\n",
    "        n_lat = ds_ii.dims['lat']\n",
    "        wl_means = np.zeros((n_wl, n_lat, n_lon))\n",
    "\n",
    "        base_year = pd.to_datetime(ds_ii.time[0].values).year\n",
    "\n",
    "        for jj, wl_jj in enumerate(levels):\n",
    "\n",
    "            wlyear = model_wl_dict[model][jj]\n",
    "            idx_ctr = wlyear - base_year\n",
    "            ds_wl = ds_ii.isel(time = slice(idx_ctr - window_size, idx_ctr + window_size + 1))\n",
    "            ds_wl_mean = ds_wl.mean(dim='time', skipna=True)\n",
    "            wl_means[jj] = ds_wl_mean[f'ndays_over_{ndays}hrs'].values\n",
    "\n",
    "        ds_out[f'ndays_over_{ndays}hrs'] = (['level','lat','lon'], wl_means)\n",
    "    ds_out['lon'] = ds_ii.lon\n",
    "    ds_out['lat'] = ds_ii.lat\n",
    "    fp_out_wl = fp_out_temp.format(ndays, model)\n",
    "    ds_out.to_netcdf(fp_out_wl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf96ef39-6a05-419d-ab10-6ed90e1a910b",
   "metadata": {},
   "source": [
    "### Calculate model ensemble median number of days per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a9e3b1-d894-4840-a3b8-4582e747bc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from days per year per warming level file.\n",
    "fp_list = glob.glob('<wildcarded output from previous section>')\n",
    "ds_list = [xr.open_dataset(fp, chunks={}) for fp in fp_list]\n",
    "ds = xr.concat(ds_list, dim='model')\n",
    "fp_out = './output/median_ndays_per_year_{0}H.tif'\n",
    "\n",
    "# Calculate model median and standard deviation\n",
    "ds_med = ds.median(dim='model').compute()\n",
    "ds_std = ds.std(dim='model').compute()\n",
    "ds_max = ds.max(dim='model').compute()\n",
    "ds_min = ds.min(dim='model').compute()\n",
    "med = ds_med.values\n",
    "std = ds_std.values\n",
    "\n",
    "# Calculate landmask\n",
    "lon2, lat2 = np.meshgrid(ds_med.lon, ds_med.lat)\n",
    "landmask = globe.is_land(lat2, lon2)\n",
    "landmaskW = np.where(~landmask)\n",
    "ds_med = ds_med.rio.write_crs(4326)\n",
    "ds_med = ds_med.rename({'lon':'x','lat':'y'})\n",
    "\n",
    "# loop over hours to save\n",
    "for ii in [3,6,9,12,15,18,21,24]:\n",
    "    ds_med[f'ndays_over_{ii}hrs'].rio.to_raster(fp_out.format(ii))\n",
    "\n",
    "# Make output filename and save\n",
    "fp = fp_out.format(6)\n",
    "ds = xr.open_dataset(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc47e00-85ad-4086-b294-60c3b5323680",
   "metadata": {},
   "source": [
    "### First warming level of LH occurrence for different numbers of days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b51d1b2-d79d-4590-b2e5-9dd64cd3f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output files\n",
    "fp_out_gt1 = './firstWL_gt1dayperyear.tif'\n",
    "fp_out_gt7 = './firstWL_gt7dayperyear.tif'\n",
    "\n",
    "# We concatenate a true layer onto our arrays in case no warming levels were found (then that concat layer will be default)...\n",
    "# ...For median\n",
    "ds_med_gt1 = np.concatenate( [(ds_med>1).values, np.ones((1, 360, 720))], axis=0 )\n",
    "ds_med_gt1_amax = np.argmax(ds_med_gt1,axis=0).astype(float) / 2 + 1\n",
    "ds_med_gt1_amax[ landmaskW[0], landmaskW[1] ] = np.nan\n",
    "\n",
    "# ...For data max\n",
    "ds_max_gt1 = np.concatenate( [(ds_max>1).values, np.ones((1, 360, 720))], axis=0 )\n",
    "ds_max_gt1_amax = np.argmax(ds_max_gt1,axis=0).astype(float) / 2 + 1\n",
    "ds_max_gt1_amax[ landmaskW[0], landmaskW[1] ] = np.nan\n",
    "\n",
    "# ...For data min\n",
    "ds_min_gt1 = np.concatenate( [(ds_min>1).values, np.ones((1, 360, 720))], axis=0 )\n",
    "ds_min_gt1_amax = np.argmax(ds_min_gt1,axis=0).astype(float) / 2 + 1\n",
    "ds_min_gt1_amax[ landmaskW[0], landmaskW[1] ] = np.nan\n",
    "\n",
    "n_r, n_c = ds_med_gt1_amax.shape\n",
    "gt1_out = np.zeros((3, n_r, n_c))\n",
    "gt1_out[0,:,:] = ds_min_gt1_amax\n",
    "gt1_out[1,:,:] = ds_med_gt1_amax\n",
    "gt1_out[2,:,:] = ds_max_gt1_amax\n",
    "\n",
    "# 7 days a year (repeat of above)\n",
    "ds_med_gt7 = np.concatenate( [(ds_med>7).values, np.ones((1, 360, 720))], axis=0 )\n",
    "ds_med_gt7_amax = np.argmax(ds_med_gt7,axis=0).astype(float) / 2 + 1\n",
    "ds_med_gt7_amax[ landmaskW[0], landmaskW[1] ] = np.nan\n",
    "\n",
    "ds_max_gt7 = np.concatenate( [(ds_max>7).values, np.ones((1, 360, 720))], axis=0 )\n",
    "ds_max_gt7_amax = np.argmax(ds_max_gt7,axis=0).astype(float) / 2 + 1\n",
    "ds_max_gt7_amax[ landmaskW[0], landmaskW[1] ] = np.nan\n",
    "\n",
    "ds_min_gt7 = np.concatenate( [(ds_min>7).values, np.ones((1, 360, 720))], axis=0 )\n",
    "ds_min_gt7_amax = np.argmax(ds_min_gt7,axis=0).astype(float) / 2 + 1\n",
    "ds_min_gt7_amax[ landmaskW[0], landmaskW[1] ] = np.nan\n",
    "\n",
    "n_r, n_c = ds_med_gt1_amax.shape\n",
    "gt7_out = np.zeros((3, n_r, n_c))\n",
    "gt7_out[0,:,:] = ds_min_gt7_amax\n",
    "gt7_out[1,:,:] = ds_med_gt7_amax\n",
    "gt7_out[2,:,:] = ds_max_gt7_amax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cd9d91-e892-41d5-b685-6fbee11d4d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output datasets and save to file\n",
    "ds_out1 = ds_med.to_dataset()[['lon','lat']]\n",
    "ds_out7 = ds_med.to_dataset()[['lon','lat']]\n",
    "\n",
    "ds_out1['band_data'] = (['Band','lat','lon'], gt1_out)\n",
    "ds_out7['band_data'] = (['Band','lat','lon'], gt7_out)\n",
    "\n",
    "ds_out1.attrs['crs'] = 'WGS84'\n",
    "ds_out7.attrs['crs'] = 'WGS84'\n",
    "\n",
    "ds_out1 = ds_out1.rename({'lon':'x','lat':'y'})\n",
    "ds_out7 = ds_out7.rename({'lon':'x','lat':'y'})\n",
    "\n",
    "ds_out1['band_data'].rio.to_raster(fp_out_gt1)\n",
    "ds_out7['band_data'].rio.to_raster(fp_out_gt7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef0833a-0f35-479a-904e-c250e01c5952",
   "metadata": {},
   "source": [
    "### Return Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9263bb62-7105-444c-b392-b05e4a8b2493",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_temp = './tolh_ndays6_{0}_ssp585.nc'\n",
    "fp_out_rp = './returnperiod_gt1dayperyear.tif'\n",
    "lon2, lat2 = np.meshgrid(ds_med.lon, ds_med.lat)\n",
    "landmask = globe.is_land(lat2, lon2)\n",
    "landmaskW = np.where(~landmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34988a7-7b89-43a6-9cbd-0857330cc806",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "# Loop over models\n",
    "for ii, model in enumerate(model_names):\n",
    "    print(ii+1, n_models, end='\\r')\n",
    "\n",
    "    # Make filename and open dataset \n",
    "    fp_ii = fp_temp.format(model)\n",
    "    ds_ii = xr.open_dataset(fp_ii).load()\n",
    "    n_lon = ds_ii.dims['lon']\n",
    "    n_lat = ds_ii.dims['lat']\n",
    "    wl_means = np.zeros((n_wl, n_lat, n_lon))\n",
    "    data_list.append([])\n",
    "    \n",
    "    base_year = pd.to_datetime(ds_ii.time[0].values).year\n",
    "\n",
    "    # Extract data for each warming level\n",
    "    for jj, wl_jj in enumerate(levels):\n",
    "        wlyear = model_wl_dict[model][jj]\n",
    "        idx_ctr = wlyear - base_year\n",
    "        data_list[ii].append( ds_ii.isel(time = slice(idx_ctr - window_size, idx_ctr + window_size))['ndays_6'].load() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e427c1b-2e32-49de-8896-7a0c260a563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define return levels (inputs) and return period array\n",
    "return_levels = [1, 5, 10, 50, 100]\n",
    "n_rl = len(return_levels)\n",
    "return_periods = np.zeros((n_rl, 6, 360, 720))\n",
    "\n",
    "# Loop over warming levels and calculate return periods\n",
    "for rr, rl in enumerate(return_levels):\n",
    "    print(rr, end='\\r')\n",
    "    for ii in range(6):\n",
    "        data_ii = [data_list[kk][ii] for kk in range(16)]\n",
    "        data_ii = [tmpds.drop('time') for tmpds in data_ii]\n",
    "        data_ii_concat = xr.concat(data_ii, dim='model')\n",
    "        data_ii_concat = data_ii_concat.stack(newdim = ('time','model')) >= rl\n",
    "        frequency_ii = data_ii_concat.sum('newdim') / data_ii_concat.sizes['newdim']\n",
    "        return_periods[rr, ii] = 1/frequency_ii\n",
    "\n",
    "# Apply mask\n",
    "return_periods[:,:,landmaskW[0], landmaskW[1]] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd621af-90e2-4c0d-8fca-6ec78d736dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to dataset\n",
    "ds_out = ds_med.to_dataset()[['lon','lat']]\n",
    "ds_out['return_period'] = (['level','lat','lon'], return_periods[0])\n",
    "ds_out = ds_out.rename({'lon':'x','lat':'y'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
