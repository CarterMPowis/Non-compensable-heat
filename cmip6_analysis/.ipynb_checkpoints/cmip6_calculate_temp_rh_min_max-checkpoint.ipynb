{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75c1ef9f-8e01-446b-b4ee-ae312d92f783",
   "metadata": {},
   "source": [
    "Preprocessing step.\n",
    "Calculate daily temperature and humidity min and max, and upload them to google bucket.\n",
    "This is used to index the lookup table for number of hours per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b420a2c1-ce4d-4cda-8d73-a930ca9df9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import os.path as path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07c89bb-7d3e-4d0b-ba5c-66090c9882a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = '<REPLACE WITH TEMPORARY DATA DIRECTORY>'\n",
    "gs_dir_tmax = f'<REPLACE WITH LOCATION OF CMIP6 TEMPERATURE DATA ON BUCKET'\n",
    "my_dir_tmax = '<REPLACE WITH OUTPUT LOCATION FOR TEMPERATURE DATA ON GOOGLE BUCKET>'\n",
    "gs_dir_tmean = f'<REPLACE WITH LOCATION OF CMIP6 TEMPERATURE DATA ON BUCKET'\n",
    "my_dir_tmean = '<REPLACE WITH OUTPUT LOCATION FOR TEMPERATURE DATA ON GOOGLE BUCKET>'\n",
    "gs_dir_rhmin = f'<REPLACE WITH LOCATION OF CMIP6 RH DATA ON BUCKET'\n",
    "my_dir_rhmin = '<REPLACE WITH OUTPUT LOCATION FOR RH DATA ON GOOGLE BUCKET>'\n",
    "gs_dir_rhmean = f'<REPLACE WITH LOCATION OF CMIP6 RH DATA ON BUCKET'\n",
    "my_dir_rhmean = '<REPLACE WITH OUTPUT LOCATION FOR RH DATA ON GOOGLE BUCKET>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc301a3-6282-43b4-b5f8-b7b3513e1bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['ACCESS-CM2', 'ACCESS-ESM1-5', 'AWI-CM-1-1-MR', 'BCC-CSM2-MR', 'CAMS-CSM1-0', 'CMCC-ESM2',\n",
    "              'CNRM-CM6-1-HR', 'CNRM-CM6-1', 'CNRM-ESM2-1', 'CanESM5', 'EC-Earth3-Veg-LR', 'EC-Earth3-Veg',\n",
    "              'EC-Earth3', 'FGOALS-g3', 'GFDL-CM4', 'GFDL-ESM4', 'HadGEM3-GC31-LL', 'HadGEM3-GC31-MM', 'INM-CM4-8',\n",
    "              'INM-CM5-0', 'IPSL-CM6A-LR', 'KIOST-ESM', 'MIROC-ES2L', 'MIROC6', 'MPI-ESM1-2-HR', 'MPI-ESM1-2-LR',\n",
    "              'MRI-ESM2-0', 'NESM3', 'NorESM2-LM', 'NorESM2-MM', 'UKESM1-0-LL']\n",
    "var_names = ['tasmax','tas','hursmin','hurs']\n",
    "\n",
    "n_models = len(model_list)\n",
    "n_vars = len(var_names)\n",
    "\n",
    "period_in = 'historical'\n",
    "period_out = '1950_1970'\n",
    "date0 = datetime(1950,1,1)\n",
    "date1 = datetime(1970,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6345482e-fc46-4644-b068-7f5e12487fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Max\n",
    "for ii, model in enumerate(model_list):\n",
    "    \n",
    "    if ii<3:\n",
    "        continue\n",
    "    \n",
    "    print(ii, end='\\r')\n",
    "    \n",
    "    # Get files\n",
    "    fp = path.join(gs_dir_tmax, f'tasmax_day_{model}_{period_in}*')\n",
    "    subprocess.run(f'gsutil -m cp {fp} {tmp_dir}', shell=True,\n",
    "                   stdout=subprocess.DEVNULL, \n",
    "                   stderr=subprocess.DEVNULL )\n",
    "    \n",
    "    # Open Files\n",
    "    ds = xr.open_mfdataset(path.join(tmp_dir, '*'))\n",
    "    ds = ds.sel(time=slice(date0, date1))\n",
    "    \n",
    "    # Write to file\n",
    "    fp_out = path.join(tmp_dir, f'tasmax_day_{model}_{period_out}.nc')\n",
    "    ds.to_netcdf(fp_out)\n",
    "    \n",
    "    # Move to my google bucket\n",
    "    subprocess.run(f'gsutil -m cp {fp_out} {my_dir_tmax}', shell=True,\n",
    "                   stdout=subprocess.DEVNULL, \n",
    "                   stderr=subprocess.DEVNULL )\n",
    "    \n",
    "    # Delete everything in tmp directory\n",
    "    subprocess.run(f'rm -f {path.join(tmp_dir, \"*\")}', shell=True,\n",
    "                   stdout=subprocess.DEVNULL, \n",
    "                   stderr=subprocess.DEVNULL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ce39e-00d8-46da-a93b-71a2b734285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Mean\n",
    "gs_dir = f'gs://cmip6_data/CMIP6_regridded_data/r288x192/daily/average_temperature/{period_in}/'\n",
    "my_dir = 'gs://fqqzlp/carter2/t_mean'\n",
    "\n",
    "for ii, model in enumerate(model_list):\n",
    "    \n",
    "    print(ii)\n",
    "    \n",
    "    # Get files\n",
    "    fp = path.join(gs_dir_tmean, f'tas_day_{model}_{period_in}*')\n",
    "    subprocess.run(f'gsutil -m cp {fp} {tmp_dir}', shell=True)\n",
    "    \n",
    "    # Open Files\n",
    "    ds = xr.open_mfdataset(path.join(tmp_dir, '*'), chunks='auto')\n",
    "    ds = ds.sel(time=slice(date0, date1))\n",
    "    \n",
    "    # Write to file\n",
    "    fp_out = path.join(tmp_dir, f'tas_day_{model}_{period_out}.nc')\n",
    "    ds.to_netcdf(fp_out)\n",
    "    \n",
    "    # Move to my google bucket\n",
    "    subprocess.run(f'gsutil -m cp {fp_out} {my_dir_tmean}', shell=True)\n",
    "    \n",
    "    # Delete everything in tmp directory\n",
    "    subprocess.run(f'rm -f {path.join(tmp_dir, \"*\")}', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed186266-9760-49a0-a8a3-6fafb23a49c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RH Min\n",
    "gs_dir = f'gs://cmip6_data/CMIP6_regridded_data/r288x192/daily/minimum_relative_humidity/{period_in}/'\n",
    "my_dir = 'gs://fqqzlp/carter2/rh_min'\n",
    "\n",
    "for ii, model in enumerate(model_list):\n",
    "    \n",
    "    print(ii)\n",
    "    \n",
    "    # Get files\n",
    "    fp = path.join(gs_dir_rhmin, f'hursmin_day_{model}_{period_in}*')\n",
    "    subprocess.run(f'gsutil -m cp {fp} {tmp_dir}', shell=True)\n",
    "    \n",
    "    # Open Files\n",
    "    ds = xr.open_mfdataset(path.join(tmp_dir, '*'), chunks='auto')\n",
    "    ds = ds.sel(time=slice(date0, date1))\n",
    "    \n",
    "    # Write to file\n",
    "    fp_out = path.join(tmp_dir, f'hursmin_day_{model}_{period_out}.nc')\n",
    "    ds.to_netcdf(fp_out)\n",
    "    \n",
    "    # Move to my google bucket\n",
    "    subprocess.run(f'gsutil -m cp {fp_out} {my_dir_rhmin}', shell=True)\n",
    "    \n",
    "    # Delete everything in tmp directory\n",
    "    subprocess.run(f'rm -f {path.join(tmp_dir, \"*\")}', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c4d90-60e7-4131-b03b-a35b29929df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RH Mean\n",
    "gs_dir = f'gs://cmip6_data/CMIP6_regridded_data/r288x192/daily/average_relative_humidity/{period_in}/'\n",
    "my_dir = 'gs://fqqzlp/carter2/rh_mean'\n",
    "\n",
    "for ii, model in enumerate(model_list):\n",
    "    \n",
    "    print(ii)\n",
    "    \n",
    "    # Get files\n",
    "    fp = path.join(gs_dir_rhmean, f'hurs_day_{model}_{period_in}*')\n",
    "    subprocess.run(f'gsutil -m cp {fp} {tmp_dir}', shell=True)\n",
    "    \n",
    "    # Open Files\n",
    "    ds = xr.open_mfdataset(path.join(tmp_dir, '*'), chunks='auto')\n",
    "    ds = ds.sel(time=slice(date0, date1))\n",
    "    \n",
    "    # Write to file\n",
    "    fp_out = path.join(tmp_dir, f'hurs_day_{model}_{period_out}.nc')\n",
    "    ds.to_netcdf(fp_out)\n",
    "    \n",
    "    # Move to my google bucket_\n",
    "    subprocess.run(f'gsutil -m cp {fp_out} {my_dir_rhmean}', shell=True)\n",
    "    \n",
    "    # Delete everything in tmp directory\n",
    "    subprocess.run(f'rm -f {path.join(tmp_dir, \"*\")}', shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
